{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5-Large - Pytorch\n",
    "This notebook shows how to fine-tune a \"T5-Large\" PyTorch model with AWS Trainium (trn1 instances) using NeuronSDK. The original implementation is provided by HuggingFace.\n",
    "\n",
    "The example has 2 stages:\n",
    "1. First compile the model using the utility `neuron_parallel_compile` to compile the model to run on the AWS Trainium device.\n",
    "1. Run the fine-tuning script to train the model based on the associated task (e.g. sst2). The training job will use 32 workers with data parallel to speed up the training.\n",
    "\n",
    "It has been tested and run on a trn1.32xlarge\n",
    "\n",
    "**Reference:** https://huggingface.co/t5-large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
       "Verify that this Jupyter notebook is running the Python kernel environment that was set up according to the [PyTorch Installation Guide](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/general/setup/torch-neuronx.html#setup-torch-neuronx). You can select the kernel from the 'Kernel -> Change Kernel' option on the top of this Jupyter notebook page."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U optimum-neuron==0.0.15 accelerate==0.23.0 datasets>=1.8.0 sentencepiece!=0.1.92 rouge-score nltk py7zr evaluate\n",
    "# now restart the kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"t5-large\"\n",
    "num_workers = 32\n",
    "batch_size = 2\n",
    "grad_accum = 1\n",
    "max_source_length = 768\n",
    "max_target_length = 200\n",
    "learning_rate = 0.0001\n",
    "dataset_name =  \"cnn_dailymail\"\n",
    "dataset_config_name= \"3.0.0\"\n",
    "num_train_epochs = 1\n",
    "model_base_name = model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Compile the model with neuron_parallel_compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "COMPILE_CMD = f\"\"\"neuron_parallel_compile torchrun --nproc_per_node {num_workers} \\\n",
    "./run_summarization.py \\\n",
    "--model_name_or_path {model_name} \\\n",
    "--num_train_epochs {num_train_epochs} \\\n",
    "--max_steps 10 \\\n",
    "--max_train_samples 128 \\\n",
    "--do_train \\\n",
    "--learning_rate {learning_rate} \\\n",
    "--per_device_train_batch_size {batch_size} \\\n",
    "--gradient_accumulation_steps {grad_accum} \\\n",
    "--report_to none \\\n",
    "--logging_steps 1 \\\n",
    "--save_total_limit 1 \\\n",
    "--bf16 \\\n",
    "--dataset_name {dataset_name} \\\n",
    "--dataset_config_name {dataset_config_name} \\\n",
    "--max_source_length {max_source_length} \\\n",
    "--max_target_length {max_target_length} \\\n",
    "--pad_to_max_length \\\n",
    "--predict_with_generate true \\\n",
    "--source_prefix 'summarize: ' \\\n",
    "--overwrite_output_dir \\\n",
    "--output_dir ./out/t5-large\"\"\"\n",
    "print(f'Running command: \\n{COMPILE_CMD}')\n",
    "if subprocess.check_call(COMPILE_CMD,shell=True):\n",
    "   print(\"There was an error with the compilation command\")\n",
    "else:\n",
    "   print(\"Compilation Success!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_CMD = f\"\"\"torchrun --nproc_per_node {num_workers} \\\n",
    "./run_summarization.py \\\n",
    "--model_name_or_path {model_name} \\\n",
    "--num_train_epochs {num_train_epochs} \\\n",
    "--max_train_samples 128 \\\n",
    "--max_eval_samples 128 \\\n",
    "--do_train \\\n",
    "--do_eval \\\n",
    "--learning_rate {learning_rate} \\\n",
    "--per_device_train_batch_size {batch_size} \\\n",
    "--per_device_eval_batch_size {batch_size} \\\n",
    "--gradient_accumulation_steps {grad_accum} \\\n",
    "--report_to none \\\n",
    "--logging_steps 1 \\\n",
    "--save_total_limit 1 \\\n",
    "--bf16 \\\n",
    "--dataset_name {dataset_name} \\\n",
    "--dataset_config_name {dataset_config_name} \\\n",
    "--max_source_length {max_source_length} \\\n",
    "--max_target_length {max_target_length} \\\n",
    "--pad_to_max_length \\\n",
    "--predict_with_generate true \\\n",
    "--source_prefix 'summarize: ' \\\n",
    "--overwrite_output_dir \\\n",
    "--output_dir ./out/run-t5-large \"\"\"\n",
    "print(f'Running command: \\n{RUN_CMD}')\n",
    "if subprocess.check_call(RUN_CMD,shell=True):\n",
    "   print(\"There was an error with the fine-tune command\")\n",
    "else:\n",
    "   print(\"Fine-tune Successful!!!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_neuronx\n",
    "import os\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from diffusers.models.unet_2d_condition import UNet2DConditionOutput\n",
    "\n",
    "from diffusers.models.cross_attention import CrossAttention\n",
    "\n",
    "\n",
    "class UNetWrap(nn.Module):\n",
    "    def __init__(self, unet):\n",
    "        super().__init__()\n",
    "        self.unet = unet\n",
    "\n",
    "    def forward(self, sample, timestep, encoder_hidden_states, cross_attention_kwargs=None):\n",
    "        out_tuple = self.unet(sample, timestep, encoder_hidden_states, return_dict=False)\n",
    "        return out_tuple\n",
    "\n",
    "class NeuronUNet(nn.Module):\n",
    "    def __init__(self, unetwrap):\n",
    "        super().__init__()\n",
    "        self.unetwrap = unetwrap\n",
    "        self.config = unetwrap.unet.config\n",
    "        self.in_channels = unetwrap.unet.in_channels\n",
    "        self.device = unetwrap.unet.device\n",
    "\n",
    "    def forward(self, sample, timestep, encoder_hidden_states, cross_attention_kwargs=None):\n",
    "        sample = self.unetwrap(sample, timestep.float().expand((sample.shape[0],)), encoder_hidden_states)[0]\n",
    "        return UNet2DConditionOutput(sample=sample)\n",
    "\n",
    "def get_attention_scores(self, query, key, attn_mask):       \n",
    "    dtype = query.dtype\n",
    "\n",
    "    if self.upcast_attention:\n",
    "        query = query.float()\n",
    "        key = key.float()\n",
    "\n",
    "    if(query.size() == key.size()):\n",
    "        attention_scores = cust_badbmm(\n",
    "            key,\n",
    "            query.transpose(-1, -2)\n",
    "        )\n",
    "\n",
    "        if self.upcast_softmax:\n",
    "            attention_scores = attention_scores.float()\n",
    "\n",
    "        attention_probs = torch.nn.functional.softmax(attention_scores, dim=1).permute(0,2,1)\n",
    "        attention_probs = attention_probs.to(dtype)\n",
    "\n",
    "    else:\n",
    "        attention_scores = cust_badbmm(\n",
    "            query,\n",
    "            key.transpose(-1, -2)\n",
    "        )\n",
    "\n",
    "        if self.upcast_softmax:\n",
    "            attention_scores = attention_scores.float()\n",
    "\n",
    "        attention_probs = torch.nn.functional.softmax(attention_scores, dim=-1)\n",
    "        attention_probs = attention_probs.to(dtype)\n",
    "        \n",
    "    return attention_probs\n",
    "\n",
    "def cust_badbmm(a, b):\n",
    "    bmm = torch.bmm(a, b)\n",
    "    scaled = bmm * 0.125\n",
    "    return scaled\n",
    "\n",
    "\n",
    "# For saving compiler artifacts\n",
    "COMPILER_WORKDIR_ROOT = 'sd2_compile_dir'\n",
    "\n",
    "model_id = \"stabilityai/stable-diffusion-2-1-base\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float32)\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "# Replace original cross-attention module with custom cross-attention module for better performance\n",
    "CrossAttention.get_attention_scores = get_attention_scores\n",
    "\n",
    "pipe.unet = NeuronUNet(UNetWrap(pipe.unet))\n",
    "\n",
    "# Compile unet - FP32\n",
    "sample_1b = torch.randn([1, 4, 64, 64])\n",
    "timestep_1b = torch.tensor(999).float().expand((1,))\n",
    "encoder_hidden_states_1b = torch.randn([1, 77, 1024])\n",
    "example_inputs = sample_1b, timestep_1b, encoder_hidden_states_1b\n",
    "\n",
    "pipe.unet.unetwrap = torch_neuronx.trace(\n",
    "    pipe.unet.unetwrap,\n",
    "    example_inputs,\n",
    "    compiler_workdir=os.path.join(COMPILER_WORKDIR_ROOT, 'unet'),\n",
    "    compiler_args=[\"--model-type=unet-inference\"]\n",
    ")\n",
    "\n",
    "# save compiled unet\n",
    "unet_filename = os.path.join(COMPILER_WORKDIR_ROOT, 'unet/model.pt')\n",
    "torch.jit.save(pipe.unet.unetwrap, unet_filename)\n",
    "\n",
    "# load previously compiled unet\n",
    "# unet_filename = os.path.join(COMPILER_WORKDIR_ROOT, 'unet/model.pt')\n",
    "# pipe.unet.unetwrap = torch.jit.load(unet_filename)\n",
    "\n",
    "# Load the compiled UNet onto two neuron cores.\n",
    "device_ids = [0,1]\n",
    "pipe.unet.unetwrap = torch_neuronx.DataParallel(pipe.unet.unetwrap, device_ids, set_dynamic_batching=False)\n",
    "\n",
    "# # Compile vae post_quant_conv\n",
    "post_quant_conv_in = torch.randn([1, 4, 64, 64])\n",
    "pipe.vae.post_quant_conv = torch_neuronx.trace(\n",
    "    pipe.vae.post_quant_conv, \n",
    "    post_quant_conv_in,\n",
    "    compiler_workdir=os.path.join(COMPILER_WORKDIR_ROOT, 'vae_post_quant_conv'),\n",
    ")\n",
    "\n",
    "# # Save the compiled vae post_quant_conv\n",
    "post_quant_conv_filename = os.path.join(COMPILER_WORKDIR_ROOT, 'vae_post_quant_conv/model.pt')\n",
    "torch.jit.save(pipe.vae.post_quant_conv, post_quant_conv_filename)\n",
    "\n",
    "# Load the previously-compiled vae post_quant_conv\n",
    "# post_quant_conv_filename = os.path.join(COMPILER_WORKDIR_ROOT, 'vae_post_quant_conv/model_cast_fp32.pt')\n",
    "# pipe.vae.post_quant_conv = torch.jit.load(post_quant_conv_filename)\n",
    "\n",
    "# Compile vae decoder\n",
    "decoder_in = torch.randn([1, 4, 64, 64])\n",
    "pipe.vae.decoder = torch_neuronx.trace(\n",
    "    pipe.vae.decoder, \n",
    "    decoder_in, \n",
    "    compiler_workdir=os.path.join(COMPILER_WORKDIR_ROOT, 'vae_decoder'),\n",
    ")\n",
    "\n",
    "# Save the compiled vae decoder\n",
    "decoder_filename = os.path.join(COMPILER_WORKDIR_ROOT, 'vae_decoder/model.pt')\n",
    "torch.jit.save(pipe.vae.decoder, decoder_filename)\n",
    "\n",
    "# # Load the previously-compiled vae decoder\n",
    "# decoder_filename = os.path.join(COMPILER_WORKDIR_ROOT, 'vae_decoder/model.pt')\n",
    "# pipe.vae.decoder = torch.jit.load(decoder_filename)\n",
    "\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "image = pipe(prompt).images[0]\n",
    "image.save(\"astronaut_rides_horse_neuron_512.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFace PixArt Alpha 1k resolution inference on trn2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**\n",
    "\n",
    "This notebook demonstrates how to compile and run the HuggingFace PixArt Alpha 1k resolution model for accelerated inference on Neuron.\n",
    "This Jupyter notebook should be run on a trn2 instance. This tutorial has a similar structure as `hf_pretrained_pixart_sigma_inference_on_inf2.ipynb` notebook, so we will not repeat the prescribed pattern and jump directly to the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# install dependencies\n",
    "!pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download the pretained pixart sigma model.\n",
    "!python neuron_pixart_sigma/cache_hf_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# compile the component models. \n",
    "!sh compile_throughput_optimized.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from diffusers import PixArtSigmaPipeline\n",
    "\n",
    "import neuronx_distributed\n",
    "import numpy as npy\n",
    "import time\n",
    "import torch\n",
    "import torch_neuronx\n",
    "\n",
    "from neuron_pixart_sigma.neuron_commons import InferenceTextEncoderWrapper\n",
    "from neuron_pixart_sigma.neuron_commons import InferenceTransformerWrapper\n",
    "from neuron_pixart_sigma.neuron_commons import SimpleWrapper\n",
    "\n",
    "from neuronx_distributed.trace import parallel_model_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPILED_MODELS_DIR = \"compile_workdir_throughput_optimized\"\n",
    "HUGGINGFACE_CACHE_DIR = \"pixart_sigma_hf_cache_dir_1024\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pipe: PixArtSigmaPipeline = PixArtSigmaPipeline.from_pretrained(\n",
    "        \"PixArt-alpha/PixArt-Sigma-XL-2-1024-MS\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        local_files_only=True,\n",
    "        cache_dir=\"pixart_sigma_hf_cache_dir_1024\")\n",
    "\n",
    "    text_encoder_model_path = f\"{COMPILED_MODELS_DIR}/text_encoder\"\n",
    "    transformer_model_path = f\"{COMPILED_MODELS_DIR}/transformer/model.pt\" \n",
    "    decoder_model_path = f\"{COMPILED_MODELS_DIR}/decoder/model.pt\"\n",
    "    post_quant_conv_model_path = f\"{COMPILED_MODELS_DIR}/post_quant_conv/model.pt\"\n",
    "\n",
    "    seqlen=300\n",
    "    text_encoder_wrapper = InferenceTextEncoderWrapper(\n",
    "        torch.bfloat16, pipe.text_encoder, seqlen\n",
    "    )\n",
    "    \n",
    "    text_encoder_wrapper.t = parallel_model_load(\n",
    "        text_encoder_model_path\n",
    "    )\n",
    "\n",
    "    transformer_wrapper = InferenceTransformerWrapper(pipe.transformer)\n",
    "    transformer_wrapper.transformer = torch_neuronx.DataParallel(\n",
    "        torch.jit.load(transformer_model_path), [0, 1, 2, 3], False # Use for trn2\n",
    "        # torch.jit.load(transformer_model_path), [0, 1, 2, 3, 4, 5, 6, 7], False # Use for trn1/inf2\n",
    "    )\n",
    "\n",
    "    vae_decoder_wrapper = SimpleWrapper(pipe.vae.decoder)\n",
    "    vae_decoder_wrapper.model = torch_neuronx.DataParallel(\n",
    "        torch.jit.load(decoder_model_path), [0, 1, 2, 3], False # Use for trn2\n",
    "        # torch.jit.load(decoder_model_path), [0, 1, 2, 3, 4, 5, 6, 7], False # Use for trn1/inf2\n",
    "    )\n",
    "    \n",
    "    vae_post_quant_conv_wrapper = SimpleWrapper(pipe.vae.post_quant_conv)\n",
    "    vae_post_quant_conv_wrapper.model = torch_neuronx.DataParallel(\n",
    "        torch.jit.load(post_quant_conv_model_path), [0, 1, 2, 3], False # Use for trn2\n",
    "        # torch.jit.load(post_quant_conv_model_path), [0, 1, 2, 3, 4, 5, 6, 7], False # Use for trn1/inf2\n",
    "    )\n",
    "    \n",
    "    pipe.text_encoder = text_encoder_wrapper\n",
    "    pipe.transformer = transformer_wrapper\n",
    "    pipe.vae.decoder = vae_decoder_wrapper\n",
    "    pipe.vae.post_quant_conv = vae_post_quant_conv_wrapper\n",
    "    \n",
    "    # Run pipeline\n",
    "    prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "    negative_prompt = \"mountains\"\n",
    "    \n",
    "    # First do a warmup run so all the asynchronous loads can finish\n",
    "    image_warmup = pipe(\n",
    "        prompt=prompt, \n",
    "        negative_prompt=negative_prompt, \n",
    "        num_images_per_prompt=4, \n",
    "        height=1024,\n",
    "        width=1024,\n",
    "        num_inference_steps=25\n",
    "    ).images[0]\n",
    "    \n",
    "\n",
    "    images = pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative_prompt,\n",
    "        num_images_per_prompt=4,\n",
    "        height=1024,\n",
    "        width=1024,\n",
    "        num_inference_steps=25\n",
    "    ).images\n",
    "    \n",
    "    for idx, img in enumerate(images): \n",
    "        img.save(f\"image_{idx}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

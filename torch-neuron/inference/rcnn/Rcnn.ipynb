{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21eddac9",
   "metadata": {},
   "source": [
    "# R-CNN for AWS Inferentia\n",
    "\n",
    "This notebook demonstrates how to compile and run a [Detectron2](https://github.com/facebookresearch/detectron2) R-CNN  model for accelerated inference on Inferentia. This notebook has the following main sections:\n",
    "\n",
    "1. Install dependencies\n",
    "1. Define preprocessing and compilation helper functions\n",
    "1. Define wrappers that extract the R-CNN ResNet backbone, RPN Head, and RoI Head for compilation on Inf1. Also define a `NeuronRCNN` wrapper that creates an optimized end-to-end Detectron2 R-CNN model for inference on Inf1\n",
    "1. Create the `NeuronRCNN` model by compiling the wrappers\n",
    "1. Run inference using the `NeuronRCNN` model\n",
    "\n",
    "#### Notebook background:\n",
    "\n",
    "The compilation wrappers and optimizations performed in this notebook are described in the [R-CNN application note](https://awsdocs-neuron-staging.readthedocs-hosted.com/en/latest/general/appnotes/torch-neuron/rcnn-app-note.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6a4ff7",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "This application note requires the following pip packages:\n",
    "\n",
    "1. `torch==1.11.0`\n",
    "1. `torch-neuron`\n",
    "1. `neuron-cc`\n",
    "1. `opencv-python`\n",
    "1. `pycocotools`\n",
    "1. `torchvision==0.12.0`\n",
    "1. `detectron2==0.6`\n",
    "\n",
    "The following section builds `torchvision` from source and installs the `Detectron2` package. It also reinstalls the Neuron packages to ensure version compability.\n",
    "\n",
    "The Torchvision `roi_align_kernel.cpp` kernel is modified to use OMP threading for multithreaded inference on CPU. This significantly improves the performance of RoI Align kernels on Inf1: OMP threading leads to a 2 - 3x RoI Align latency reduction compared to the default `roi_align_kernel.cpp` kernel configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea316acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install python3.7-dev for pycocotools (a Detectron2 dependency)\n",
    "!sudo apt install python3.7-dev -y\n",
    "\n",
    "# Install Neuron packages\n",
    "!pip config set global.extra-index-url https://pip.repos.neuron.amazonaws.com\n",
    "!pip uninstall -y torchvision\n",
    "!pip install --force-reinstall torch-neuron==1.11.0.* neuron-cc[tensorflow] \"protobuf==3.20.1\" ninja opencv-python\n",
    "\n",
    "# Change cuda to 10.2 for Detectron2\n",
    "!sudo rm /usr/local/cuda\n",
    "!sudo ln -s /usr/local/cuda-10.2 /usr/local/cuda\n",
    "\n",
    "# Install Torchvision 0.12.0 from source\n",
    "!git clone -b release/0.12 https://github.com/pytorch/vision.git\n",
    "\n",
    "# Update the RoI Align kernel to use OMP multithreading\n",
    "with open('vision/torchvision/csrc/ops/cpu/roi_align_kernel.cpp', 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Enable OMP Multithreading and set the number of threads to 4\n",
    "old = \"// #pragma omp parallel for num_threads(32)\"\n",
    "new = \"#pragma omp parallel for num_threads(4)\"\n",
    "content = content.replace(old, new)\n",
    "\n",
    "# Re-write the file\n",
    "with open('vision/torchvision/csrc/ops/cpu/roi_align_kernel.cpp', 'w') as file:\n",
    "    file.write(content)\n",
    "\n",
    "# Build Torchvision with OMP threading\n",
    "!cd vision && CFLAGS=\"-fopenmp\" python setup.py bdist_wheel\n",
    "%pip install vision/dist/*.whl\n",
    "\n",
    "# Install Detectron2 release v0.6\n",
    "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git@v0.6'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64fb31f",
   "metadata": {},
   "source": [
    "## Preprocessing and compilation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9872e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    # Configure the R-CNN model\n",
    "    CONFIG_FILE = \"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"\n",
    "    WEIGHTS_FILE = \"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE))\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(WEIGHTS_FILE)\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "    cfg.MODEL.DEVICE = 'cpu' # Send to CPU for Neuron Tracing\n",
    "\n",
    "    # Create the R-CNN predictor wrapper\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014b90d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "def get_image():\n",
    "\n",
    "    # Get a sample image\n",
    "    filename = 'input.jpg'\n",
    "    if not os.path.exists(filename):\n",
    "        url = \"http://images.cocodataset.org/val2017/000000439715.jpg\"\n",
    "        urllib.request.urlretrieve(url, filename)\n",
    "    return filename\n",
    "\n",
    "\n",
    "def preprocess(original_image, predictor):\n",
    "    \"\"\"\n",
    "    A basic preprocessing function that sets the input height=800 and\n",
    "    input width=800. The function is derived from the preprocessing\n",
    "    steps in the Detectron2 `DefaultPredictor` module.\n",
    "    \"\"\"\n",
    "\n",
    "    height, width = original_image.shape[:2]\n",
    "    resize_func = predictor.aug.get_transform(original_image)\n",
    "    resize_func.new_h = 800 # Override height\n",
    "    resize_func.new_w = 800 # Override width\n",
    "    image = resize_func.apply_image(original_image)\n",
    "    image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n",
    "    inputs = {\"image\": image, \"height\": height, \"width\": width}\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595728aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_neuron\n",
    "from typing import Any, Union, Callable\n",
    "\n",
    "def compile_or_load(\n",
    "    model: Union[Callable, torch.nn.Module],\n",
    "    example_inputs: Any,\n",
    "    filename: str,\n",
    "    **kwargs\n",
    ") -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    Load a Neuron module if it exists. Otherwise, compile the model for Inf1\n",
    "    and save it as provided filename.\n",
    "\n",
    "    model: A module or function which defines a torch model or computation.\n",
    "    example_inputs: An example set of inputs which will be passed to the\n",
    "        `model` during compilation.\n",
    "    filename: Name of the compiled model\n",
    "    kwargs: Extra `torch_neuron.trace` kwargs\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(filename):\n",
    "        with torch.no_grad():\n",
    "            compiled_model = torch_neuron.trace(model, example_inputs, **kwargs)\n",
    "        torch.jit.save(compiled_model, filename)\n",
    "\n",
    "    compiled_model = torch.jit.load(filename)\n",
    "    return compiled_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7243c7",
   "metadata": {},
   "source": [
    "## Neuron compilation wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e385f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.modeling.meta_arch.rcnn import GeneralizedRCNN\n",
    "\n",
    "class NeuronFusedBackboneRPNHead(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Wrapper to compile the fused ResNet backbone and RPN Head.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: GeneralizedRCNN) -> None:\n",
    "        super().__init__()\n",
    "        self.backbone = model.backbone\n",
    "        self.rpn_head = model.proposal_generator.rpn_head\n",
    "        self.in_features = model.proposal_generator.in_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        features_ = [features[f] for f in self.in_features]\n",
    "        return self.rpn_head(features_), features\n",
    "\n",
    "\n",
    "class BackboneRPN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Wrapper that uses the compiled `neuron_backbone_rpn` instead\n",
    "    of the original backbone and RPN Head. We copy the remainder\n",
    "    of the RPN `forward` code (`predictor.model.proposal_generator.forward`)\n",
    "    to create a \"fused\" backbone + RPN module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: GeneralizedRCNN) -> None:\n",
    "        super().__init__()\n",
    "        self.backbone_rpn_head = NeuronFusedBackboneRPNHead(model)\n",
    "        self._rpn = model.proposal_generator\n",
    "        self.in_features = model.proposal_generator.in_features\n",
    "\n",
    "    def forward(self, images):\n",
    "        preds, features = self.backbone_rpn_head(images.tensor)\n",
    "        features_ = [features[f] for f in self.in_features]\n",
    "        pred_objectness_logits, pred_anchor_deltas = preds\n",
    "        anchors = self._rpn.anchor_generator(features_)\n",
    "\n",
    "        # Transpose the Hi*Wi*A dimension to the middle:\n",
    "        pred_objectness_logits = [\n",
    "            # (N, A, Hi, Wi) -> (N, Hi, Wi, A) -> (N, Hi*Wi*A)\n",
    "            score.permute(0, 2, 3, 1).flatten(1)\n",
    "            for score in pred_objectness_logits\n",
    "        ]\n",
    "        pred_anchor_deltas = [\n",
    "            # (N, A*B, Hi, Wi) -> (N, A, B, Hi, Wi) -> (N, Hi, Wi, A, B) -> (N, Hi*Wi*A, B)\n",
    "            x.view(x.shape[0], -1, self._rpn.anchor_generator.box_dim,\n",
    "                   x.shape[-2], x.shape[-1])\n",
    "            .permute(0, 3, 4, 1, 2)\n",
    "            .flatten(1, -2)\n",
    "            for x in pred_anchor_deltas\n",
    "        ]\n",
    "\n",
    "        proposals = self._rpn.predict_proposals(\n",
    "            anchors, pred_objectness_logits, pred_anchor_deltas, images.image_sizes\n",
    "        )\n",
    "        return proposals, features\n",
    "\n",
    "\n",
    "class NeuronBoxHeadBoxPredictor(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Wrapper that extracts the RoI Box Head and Box Predictor\n",
    "    for compilation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: GeneralizedRCNN) -> None:\n",
    "        super().__init__()\n",
    "        self.roi_heads = model.roi_heads\n",
    "\n",
    "    def forward(self, box_features):\n",
    "        box_features = self.roi_heads.box_head(box_features)\n",
    "        predictions = self.roi_heads.box_predictor(box_features)\n",
    "        return predictions\n",
    "\n",
    "\n",
    "class ROIHead(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Wrapper that combines the compiled `roi_heads` into the\n",
    "    rest of the RoI module. The `_forward_box` and `forward`\n",
    "    functions are from the `predictor.model.roi_heads` module.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: GeneralizedRCNN) -> None:\n",
    "        super().__init__()\n",
    "        self.roi_heads = model.roi_heads\n",
    "        self.neuron_box_head_predictor = NeuronBoxHeadBoxPredictor(model)\n",
    "\n",
    "    def _forward_box(self, features, proposals):\n",
    "        features = [features[f] for f in self.roi_heads.box_in_features]\n",
    "        box_features = self.roi_heads.box_pooler(\n",
    "            features, [x.proposal_boxes for x in proposals])\n",
    "        predictions = self.neuron_box_head_predictor(box_features)\n",
    "        pred_instances, _ = self.roi_heads.box_predictor.inference(\n",
    "            predictions, proposals)\n",
    "        return pred_instances\n",
    "\n",
    "    def forward(self, images, features, proposals, targets=None):\n",
    "        pred_instances = self._forward_box(features, proposals)\n",
    "        pred_instances = self.roi_heads.forward_with_given_boxes(\n",
    "            features, pred_instances)\n",
    "        return pred_instances, {}\n",
    "\n",
    "\n",
    "class NeuronRCNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Wrapper that uses the fused backbone + RPN module and the optimized RoI\n",
    "    Heads wrapper\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model: GeneralizedRCNN) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # Create fused Backbone + RPN\n",
    "        self.backbone_rpn = BackboneRPN(model)\n",
    "\n",
    "        # Create Neuron RoI Head\n",
    "        self.roi_heads = ROIHead(model)\n",
    "\n",
    "        # Define pre and post-processing functions\n",
    "        self.preprocess_image = model.preprocess_image\n",
    "        self._postprocess = model._postprocess\n",
    "\n",
    "    def forward(self, batched_inputs):\n",
    "        images = self.preprocess_image(batched_inputs)\n",
    "        proposals, features = self.backbone_rpn(images)\n",
    "        results, _ = self.roi_heads(images, features, proposals, None)\n",
    "        return self._postprocess(results, batched_inputs, images.image_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25265c70",
   "metadata": {},
   "source": [
    "## Compile the fused backbone + RPN Head and RoI Head for inference on Inf1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a508953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile the combined backbone and RPN Head wrapper\n",
    "backbone_rpn_filename = 'backbone_rpn.pt'\n",
    "\n",
    "predictor = get_model()\n",
    "backbone_rpn_wrapper = NeuronFusedBackboneRPNHead(predictor.model)\n",
    "backbone_rpn_wrapper.eval()\n",
    "\n",
    "example = torch.rand([1, 3, 800, 800])\n",
    "neuron_backbone_rpn_head = compile_or_load(backbone_rpn_wrapper, example, backbone_rpn_filename, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f456a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile the RoI Head wrapper\n",
    "roi_head_filename = 'box_head_predictor.pt'\n",
    "\n",
    "predictor = get_model()\n",
    "box_head_predictor = NeuronBoxHeadBoxPredictor(predictor.model)\n",
    "box_head_predictor.eval()\n",
    "\n",
    "example = torch.rand([1000, 256, 7, 7])\n",
    "neuron_box_head_predictor = compile_or_load(box_head_predictor, example, roi_head_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662dea13",
   "metadata": {},
   "source": [
    "## Neuron R-CNN Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f501de66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an R-CNN on CPU\n",
    "predictor = get_model()\n",
    "\n",
    "# Create the Neuron R-CNN on CPU\n",
    "neuron_rcnn = NeuronRCNN(predictor.model)\n",
    "neuron_rcnn.eval()\n",
    "\n",
    "# Inject the Neuron compiled models\n",
    "neuron_rcnn.backbone_rpn.backbone_rpn_head = neuron_backbone_rpn_head\n",
    "neuron_rcnn.roi_heads.neuron_box_head_predictor = neuron_box_head_predictor\n",
    "\n",
    "# Download a sample image from the COCO dataset and read it\n",
    "image_filename = get_image()\n",
    "image = cv2.imread(image_filename)\n",
    "inputs = preprocess(image, get_model())\n",
    "\n",
    "# Run inference using the sample image and print the output\n",
    "print(neuron_rcnn([inputs]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Neuron PyTorch)",
   "language": "python",
   "name": "pytorch_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
